{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffbd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "import kpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7764c",
   "metadata": {},
   "source": [
    "# Psudo-code to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1abc6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3(local_file_name, s3_bucket, s3_object_key):\n",
    "    \"\"\" \n",
    "    reference: \n",
    "    https://stackoverflow.com/questions/41827963/\n",
    "    track-download-progress-of-s3-file-using-boto3-and-callbacks\n",
    "    \"\"\"\n",
    "\n",
    "    meta_data = s3_client.head_object(Bucket=s3_bucket, Key=s3_object_key)\n",
    "    total_length = int(meta_data.get('ContentLength', 0))\n",
    "    downloaded = 0\n",
    "\n",
    "    def progress(chunk):\n",
    "        nonlocal downloaded\n",
    "        downloaded += chunk\n",
    "        done = int(50 * downloaded / total_length)\n",
    "        sys.stdout.write(\"\\r[%s%s]\" % ('=' * done, ' ' * (50-done)) )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print(f'Downloading {s3_object_key}')\n",
    "    with open(local_file_name, 'wb') as f:\n",
    "        s3_client.download_fileobj(s3_bucket, s3_object_key, f, Callback=progress)\n",
    "        \n",
    "\n",
    "def download_data(scenario):\n",
    "    \"\"\"\n",
    "    Download results (ActivitySim and Skims) of scenario in a tmp folder. \n",
    "    \n",
    "    Parameters: \n",
    "    -------------\n",
    "    - scenario: str. scenario name \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    data_exist = os.path.isdir('tmp/{}'.format(scenario))\n",
    "    \n",
    "    if data_exist:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        s3_bucket = 'carb-results'\n",
    "\n",
    "        #Download Asim results\n",
    "        asim_local_file = \"tmp/{}_asim_output.zip\".format(scenario)\n",
    "        asim_s3_object_key = \"{}/asim_outputs_2022.zip\".format(scenario)\n",
    "        download_s3(asim_local_file, s3_bucket , asim_s3_object_key)\n",
    "\n",
    "        #Unzip Asim Results\n",
    "        with ZipFile(asim_local_file, 'r') as zipObj:\n",
    "            zipObj.extractall('tmp')\n",
    "\n",
    "         #Download Skims\n",
    "        skims_local_file = \"tmp/{}/skims.omx\".format(scenario)\n",
    "        skims_s3_object_key = \"{}/skims.omx\".format(scenario)\n",
    "        download_s3(skims_local_file, s3_bucket , skims_s3_object_key)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def delete_data(scenario):\n",
    "    if (scenario == '01_base_000') or (scenario == 'ex_1'):\n",
    "        pass\n",
    "    else:\n",
    "        os.rmdir('tmp/{}'.format(scenario))\n",
    "        os.remove(\"tmp/{}_asim_output.zip\".format(scenario))\n",
    "    return None\n",
    "    \n",
    "def add_scenario_changes(df, policy_changes):\n",
    "    \"\"\" \n",
    "    Adds the scenario_id percentual change columns df\n",
    "    \n",
    "    Parameters: \n",
    "    ------------\n",
    "    df: pandas DataFrame. Policy resutls \n",
    "    policy_changes. dict. Dictionary with percental \n",
    "                          change by policy and scenario. \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df with <scenario_ids>_%change columns. \n",
    "    \n",
    "    \"\"\"\n",
    "    changes = pd.DataFrame(policy_changes).T\n",
    "    changes.index.set_names('policy', inplace = True)\n",
    "    return df.join(changes, how = 'outer',lsuffix='_metric', rsuffix=\"_%change\")\n",
    "\n",
    "def scenario_elasticities(df):\n",
    "    \"\"\"\n",
    "    Estimates scenario elasticity. \n",
    "    \"\"\"\n",
    "    metrics = df[df.columns[df.columns.str.contains('_metric')]]\n",
    "    change = df[df.columns[df.columns.str.contains('_%change')]].values\n",
    "    baseline = df['base_line']\n",
    "    \n",
    "    elasticity = (metrics.div(baseline, axis = 0) - 1).div(change, axis = 'columns')\n",
    "    elasticity.columns = elasticity.columns.str[:11] \n",
    "    elasticity = elasticity.add_suffix('elasticity')\n",
    "    return df.join(elasticity)\n",
    "\n",
    "def mean_elasticity(df):\n",
    "    scenario_elasticities = df[df.columns[df.columns.str.contains('_elasticity')]]\n",
    "    mean = scenario_elasticities.mean(axis = 1)\n",
    "    df['mean_elasticity'] = mean\n",
    "    return df\n",
    "\n",
    "def common_entries(dcts):\n",
    "    \"\"\"\n",
    "    Zip for dicts\n",
    "    Reference: https://stackoverflow.com/questions/16458340/python-equivalent-of-zip-for-dictionaries\n",
    "    Change code to return a dictionary instead. \n",
    "    \"\"\"\n",
    "    if not dcts:\n",
    "        return\n",
    "    dict_ = {}\n",
    "    for i in set(dcts[0]).intersection(*dcts[1:]):\n",
    "        dict_[i] = tuple(d[i] for d in dcts)\n",
    "    return dict_\n",
    "\n",
    "def kpis_scenario(policy, scenario, scenario_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    results_exist = os.path.isfile('kpis/{}.yaml'.format(scenario))\n",
    "    if results_exist:\n",
    "        metrics = kpi.read_yaml('kpis/{}.yaml'.format(scenario))\n",
    "        metrics['policy'] = policy\n",
    "        \n",
    "    else: \n",
    "        download_data(scenario)\n",
    "        metrics = kpi.get_scenario_results(policy, scenario, scenario_id)\n",
    "        kpi.save_yaml('kpis/{}.yaml'.format(scenario), metrics)\n",
    "    \n",
    "    kpis = list(set(metrics.keys()) - set(['policy', 'name']))\n",
    "    dfs_dict = {}\n",
    "    \n",
    "    for i in kpis:\n",
    "        try:\n",
    "            n_categories = len(metrics[i])\n",
    "            categories = metrics[i].keys()\n",
    "            baselines = metrics[i].values()\n",
    "\n",
    "        except TypeError:\n",
    "            n_categories = 1\n",
    "            categories = 'none'\n",
    "            baselines = [metrics[i]]\n",
    "            \n",
    "        scenario_name = metrics['name']\n",
    "\n",
    "        df = pd.DataFrame({'policy': [metrics['policy']] * n_categories , \n",
    "                           'category': categories,\n",
    "                           '{}'.format(scenario_name): baselines})\n",
    "        \n",
    "        df = df.set_index(['policy','category'])\n",
    "        dfs_dict[i] = df\n",
    "    \n",
    "#     delete_data(scenario)\n",
    "    return dfs_dict\n",
    "\n",
    "def save_df(name, df):\n",
    "    df.to_csv('kpis/summary/{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65606e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_scenarios = {'policy_one': {'base_line':'ex_1',\n",
    "                                   'scenario_1':'ex_2', \n",
    "                                   'scenario_2':'ex_3'},\n",
    "                    'policy_two': {'base_line':'ex_1',\n",
    "                                   'scenario_1':'ex_4', \n",
    "                                   'scenario_2':'ex_5'}}\n",
    "\n",
    "policy_changes = {'policy_one': {'scenario_1':0.25, \n",
    "                                 'scenario_2':-0.25},\n",
    "                  'policy_two': {'scenario_1':0.1, \n",
    "                                 'scenario_2':0.25}}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    metrics_list = []\n",
    "\n",
    "    for policy, scenarios in policy_scenarios.items(): \n",
    "        \n",
    "        scenario_list = [kpis_scenario(policy,s,s_id) for s_id,s in scenarios.items()]\n",
    "        iterable = common_entries(scenario_list)\n",
    "        scenario_list = {k:pd.concat(v, axis = 1) for k, v in iterable.items()}\n",
    "        metrics_list.append(scenario_list)\n",
    "    \n",
    "    iterable = common_entries(metrics_list)\n",
    "    dfs = {k:pd.concat(v, axis = 0) for k, v in iterable.items()}\n",
    "    dfs = {k:add_scenario_changes(v, policy_changes) for k, v in dfs.items()}\n",
    "    dfs = {k:scenario_elasticities(v) for k, v in dfs.items()}\n",
    "    dfs = {k:mean_elasticity(v) for k, v in dfs.items()}\n",
    "    [save_df(name, df) for name, df in dfs.items()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
