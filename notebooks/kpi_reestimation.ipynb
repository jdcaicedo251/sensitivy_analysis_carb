{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moderate-collar",
   "metadata": {},
   "source": [
    "# Re-estimate KPIs \n",
    "\n",
    "There are some improvements and changes that are done to the KPIs, and I need to re-estimate some of them. However, all the data to re-estimate them is in the AWS S3 Buckets, and it is very expensive to download all. The idea of this code is to automate the process to estimate and just let it run. \n",
    "\n",
    "For each policy:\n",
    "\n",
    "- Download trips, households, persons, and skims tables\n",
    "- Run kpy.py\n",
    "- Convert result in yaml file\n",
    "- Upload modified results to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openmatrix as omx\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO,\n",
    "    format='%(asctime)s %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "separate-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "def read_csv(fpath, index_col = None, dytpe = None):\n",
    "    bucket_name = \"carb-results\"\n",
    "    obj = s3.get_object(Bucket = bucket_name, Key = fpath)\n",
    "    \n",
    "    return pd.read_csv(obj['Body'], index_col = index_col, dtype = dytpe)\n",
    "\n",
    "def download_s3(local_file_name,s3_bucket,s3_object_key):\n",
    "    \"\"\"\n",
    "    reference:\n",
    "    https://stackoverflow.com/questions/41827963/\n",
    "    track-download-progress-of-s3-file-using-boto3-and-callbacks\n",
    "    \"\"\"\n",
    "\n",
    "    meta_data = s3.head_object(Bucket=s3_bucket, Key=s3_object_key)\n",
    "    total_length = int(meta_data.get('ContentLength', 0))\n",
    "    downloaded = 0\n",
    "\n",
    "    def progress(chunk):\n",
    "        nonlocal downloaded\n",
    "        downloaded += chunk\n",
    "        done = int(50 * downloaded / total_length)\n",
    "        sys.stdout.write(\"\\r[%s%s]\" % ('=' * done, ' ' * (50-done)) )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    logger.info(f'Downloading {s3_object_key}')\n",
    "    with open(local_file_name, 'wb') as f:\n",
    "        s3.download_fileobj(s3_bucket, s3_object_key, f, Callback=progress)\n",
    "        \n",
    "def upload_file_s3(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "\n",
    "    reference: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chief-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "### UTILS ####\n",
    "##############\n",
    "\n",
    "def read_policy_settings():\n",
    "    \"\"\" Read policy settings\"\"\"\n",
    "    a_yaml_file = open('policy_settings.yaml')\n",
    "    settings = yaml.load(a_yaml_file, Loader=yaml.FullLoader)\n",
    "    return settings\n",
    "\n",
    "\n",
    "def read_yaml(path):\n",
    "    a_yaml_file = open(path)\n",
    "    settings = yaml.load(a_yaml_file, Loader=yaml.FullLoader)\n",
    "    return settings\n",
    "\n",
    "\n",
    "def save_yaml(path, file):\n",
    "    with open(path, 'w') as outfile:\n",
    "        yaml.dump(file, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def get_metric(metric, results):\n",
    "    values = []\n",
    "    names = []\n",
    "    for arg in results:\n",
    "        values.append(arg[metric])\n",
    "        names.append(arg['name'])\n",
    "    return values, names\n",
    "\n",
    "def build_df_multi(values, names):\n",
    "    dfs = []\n",
    "    for v,n in zip(values,names):\n",
    "        df = pd.DataFrame.from_dict(data = v, orient = 'index')\n",
    "        df['name'] =  n\n",
    "        df.reset_index(inplace = True)\n",
    "        df.columns = ['category','values','name']\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "############################\n",
    "### PROCESSING RESULTS ####\n",
    "###########################\n",
    "\n",
    "def od_matrix_lookup(origin, destination, matrix):\n",
    "    ''' Returns the distance between origin and estiantion in miles\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - origing: 1-d array-like. origins ID\n",
    "    - destination: 1- d array_like. destination ID\n",
    "    - matrix: 2-d array-like. Origin-destiantion matrix for a given metric.\n",
    "                              Rows are origins, columns are destinations\n",
    "\n",
    "    Returns:\n",
    "    1-d array of the origin-destination metric.\n",
    "    '''\n",
    "    assert origin.ndim == 1, 'origin should be a 1-d array'\n",
    "    assert destination.ndim == 1, 'destination should be 1-d array'\n",
    "    assert matrix.ndim == 2, 'distance matrix should be 2-d array'\n",
    "    assert origin.shape == destination.shape, 'origin and destination should have the same shape'\n",
    "\n",
    "    #Transform array-like to numpy array in case they are not\n",
    "    #Substract 1 because distance matrix starts in ZERO\n",
    "    origin = np.array(origin) - 1\n",
    "    destination = np.array(destination) - 1\n",
    "    return matrix[origin, destination]\n",
    "\n",
    "\n",
    "def od_matrix__time_lookup(period, mode, origin, destination, matrix):\n",
    "    ''' Returns the an 0-D pair value by period and mode.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - perdiod: int.\n",
    "        - 'EA'= 0\n",
    "        - 'AM'= 1\n",
    "        - 'MD'= 2\n",
    "        - 'PM'= 3\n",
    "        - 'EV'= 4\n",
    "    - mode: int.\n",
    "        -'DRIVEALONEFREE': 0,\n",
    "        -'DRIVEALONEPAY':1,\n",
    "        -'SHARED2FREE': 2,\n",
    "        -'SHARED3FREE': 3,\n",
    "        -'SHARED2PAY':4,\n",
    "        -'SHARED3PAY':5,\n",
    "        -'WALK': 6,\n",
    "        -'BIKE': 7,\n",
    "        -'WALK_HVY': 8,\n",
    "        -'WALK_LOC': 9,\n",
    "        -'WALK_EXP': 10,\n",
    "        -'WALK_COM': 11,\n",
    "        -'WALK_LRF': 12,\n",
    "        -'DRIVE_HVY': 13,\n",
    "        -'DRIVE_LOC': 14,\n",
    "        -'DRIVE_EXP': 15,\n",
    "        -'DRIVE_COM': 16,\n",
    "        -'DRIVE_LRF': 17,\n",
    "        -'TNC_SINGLE': 18,\n",
    "        -'TNC_SHARED': 19,\n",
    "        -'TAXI': 20\n",
    "    - origing: 1-d array-like. origins ID\n",
    "    - destination: 1- d array_like. destination ID\n",
    "    - matrix: 4-d array-like. Travel Time skims. Each dimension correspond to:\n",
    "        - period\n",
    "        - mode_index\n",
    "        - origin\n",
    "        - destiantion\n",
    "\n",
    "    Returns:\n",
    "    1-d array of the origin-destination metric.\n",
    "    '''\n",
    "    assert origin.ndim == 1, 'origin should be a 1-d array'\n",
    "    assert destination.ndim == 1, 'destination should be 1-d array'\n",
    "    assert period.ndim == 1, 'origin should be a 1-d array'\n",
    "    assert period.ndim == 1, 'destination should be 1-d array'\n",
    "    assert matrix.ndim == 4, 'distance matrix should be 4-d array'\n",
    "    assert origin.shape == destination.shape, 'origin and destination should have the same shape'\n",
    "\n",
    "    #Transform array-like to numpy array in case they are not\n",
    "    #Substract 1 because distance matrix starts in ZERO\n",
    "    origin = np.array(origin) - 1\n",
    "    destination = np.array(destination) - 1\n",
    "    return matrix[period, mode, origin, destination]\n",
    "\n",
    "def time_skims(skims):\n",
    "    \"\"\"\n",
    "    Return time skims for each mode of transportation.\n",
    "    Time Period Index:\n",
    "    - 'EA'= 0\n",
    "    - 'AM'= 1\n",
    "    - 'MD'= 2\n",
    "    - 'PM'= 3\n",
    "    - 'EV'= 4\n",
    "    Mode Index:\n",
    "    -'DRIVEALONEFREE': 0,\n",
    "    -'DRIVEALONEPAY':1,\n",
    "    -'SHARED2FREE': 2,\n",
    "    -'SHARED3FREE': 3,\n",
    "    -'SHARED2PAY':4,\n",
    "    -'SHARED3PAY':5,\n",
    "    -'WALK': 6,\n",
    "    -'BIKE': 7,\n",
    "    -'WALK_HVY': 8,\n",
    "    -'WALK_LOC': 9,\n",
    "    -'WALK_EXP': 10,\n",
    "    -'WALK_COM': 11,\n",
    "    -'WALK_LRF': 12,\n",
    "    -'DRIVE_HVY': 13,\n",
    "    -'DRIVE_LOC': 14,\n",
    "    -'DRIVE_EXP': 15,\n",
    "    -'DRIVE_COM': 16,\n",
    "    -'DRIVE_LRF': 17,\n",
    "    -'TNC_SINGLE': 0,\n",
    "    -'TNC_SHARED': 0,\n",
    "    -'TAXI': 0\n",
    "\n",
    "    Return:\n",
    "    - four-dimensional matrix with travel times. (time_period, mode, origin, destination)\n",
    "    \"\"\"\n",
    "    periods = ['EA', 'AM', 'MD', 'PM', 'EV']\n",
    "    driving_modes = ['SOV', 'SOVTOLL','HOV2','HOV2TOLL', 'HOV3','HOV3TOLL']\n",
    "    transit_modes = ['HVY','LOC','EXP','COM','LRF']\n",
    "\n",
    "    time_skims = []\n",
    "    for period in periods:\n",
    "        driving_skims = []\n",
    "        walk_transit = []\n",
    "        drive_transit = []\n",
    "        for mode in driving_modes:\n",
    "            time_mtx = np.array(skims['{0}_TIME__{1}'.format(mode, period)])\n",
    "            driving_skims.append(time_mtx)\n",
    "\n",
    "        for mode in transit_modes:\n",
    "            walk_time_skim = (np.array(skims['WLK_{0}_WLK_WAIT__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['WLK_{0}_WLK_IWAIT__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['WLK_{0}_WLK_XWAIT__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['WLK_{0}_WLK_WAUX__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['WLK_{0}_WLK_TOTIVT__{1}'.format(mode, period)]))/100\n",
    "            walk_transit.append(walk_time_skim)\n",
    "\n",
    "            drive_time_skim = (np.array(skims['DRV_{0}_WLK_DTIM__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['DRV_{0}_WLK_IWAIT__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['DRV_{0}_WLK_XWAIT__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['DRV_{0}_WLK_WAUX__{1}'.format(mode, period)]) +\\\n",
    "             np.array(skims['DRV_{0}_WLK_TOTIVT__{1}'.format(mode, period)]))/100\n",
    "            drive_transit.append(drive_time_skim)\n",
    "\n",
    "        bike_time = np.array(skims['DISTBIKE'])*60/12 #12 miles/hour\n",
    "        walk_time = np.array(skims['DISTWALK'])*60/3 #3 miles/hour\n",
    "\n",
    "        period_time_skims = np.stack((driving_skims + \\\n",
    "                                      [walk_time] + \\\n",
    "                                      [bike_time] + \\\n",
    "                                      walk_transit + \\\n",
    "                                      drive_transit))\n",
    "\n",
    "        time_skims.append(period_time_skims)\n",
    "\n",
    "    return np.stack(time_skims)\n",
    "\n",
    "def driving_skims(skims):\n",
    "    \"\"\"\n",
    "    Return time skims for each mode of transportation.\n",
    "    Time Period Index:\n",
    "    - 'EA'= 0\n",
    "    - 'AM'= 1\n",
    "    - 'MD'= 2\n",
    "    - 'PM'= 3\n",
    "    - 'EV'= 4\n",
    "    Mode Index:\n",
    "    -'DRIVE_HVY': 0,\n",
    "    -'DRIVE_LOC': 1,\n",
    "    -'DRIVE_EXP': 2,\n",
    "    -'DRIVE_COM': 3,\n",
    "    -'DRIVE_LRF': 4,\n",
    "    - OTHER MODE': 5\n",
    "\n",
    "    Return:\n",
    "    - four-dimensional matrix. (time_period, mode, origin, destination)\n",
    "    \"\"\"\n",
    "    periods = ['EA', 'AM', 'MD', 'PM', 'EV']\n",
    "    transit_modes = ['HVY','LOC','EXP','COM','LRF']\n",
    "\n",
    "    time_skims = []\n",
    "    for period in periods:\n",
    "        driving_access_skims = []\n",
    "        for mode in transit_modes:\n",
    "            drive_access_skim = (np.array(skims['DRV_{0}_WLK_DDIST__{1}'.format(mode, period)]))/100\n",
    "            driving_access_skims.append(drive_access_skim)\n",
    "            shape = drive_access_skim.shape\n",
    "\n",
    "\n",
    "        period_time_skims = np.stack(driving_access_skims + [np.zeros(shape)])\n",
    "\n",
    "        time_skims.append(period_time_skims)\n",
    "\n",
    "    return np.stack(time_skims)\n",
    "\n",
    "def add_results_variables(settings, trips, households, persons, skims, land_use):\n",
    "    # trip_ids = [ 504934577, 1751074894, 1777578817, 1456859106,  603528097,\n",
    "    #         1976026805,  533494525,  289144125, 1633307365, 1638300725,\n",
    "    #         1467097413,  157430480, 1940255009,  914568381,  523906186,\n",
    "    #         1504426761, 1971365534, 1962963501, 1186364457, 1094031193]\n",
    "    # df = trips[trips.index.isin(trip_ids)].copy()\n",
    "    df = trips.copy()\n",
    "\n",
    "    #Skims values\n",
    "    dist = np.array(skims['DIST'])\n",
    "    time_skims_final = time_skims(skims)\n",
    "    driving_access_skims = driving_skims(skims)\n",
    "\n",
    "    # Mappings\n",
    "    carb_mode_mapping = settings['carb_mode_mapping']\n",
    "    mode_index_mapping = settings['mode_index_mapping']\n",
    "    drv_acc_mode_index_mapping = settings['driving_access_mode_index_mapping']\n",
    "    commute_mapping = settings['commute_mapping']\n",
    "    ivt_mapping = settings['ivt_mapping']\n",
    "    hispanic = settings['hispanic']\n",
    "    county_mapping = settings['county_mapping']\n",
    "    area_type = settings['area_type']\n",
    "\n",
    "    df['dist_miles'] = od_matrix_lookup(df.origin, df.destination, dist)\n",
    "    df['carb_mode'] = df.trip_mode.replace(carb_mode_mapping)\n",
    "    df['commute'] = df.primary_purpose.replace(commute_mapping)\n",
    "    df['period'] = pd.cut(df.depart, (0,5,10,15,19,24), labels = [0,1,2,3,4]).astype(int)\n",
    "    df['mode_index'] = df.trip_mode.replace(mode_index_mapping)\n",
    "    df['travel_time'] = od_matrix__time_lookup(df.period, df.mode_index,\n",
    "                                              df.origin, df.destination,\n",
    "                                              time_skims_final)\n",
    "    df['driving_access_mode_index'] = df.trip_mode.replace(drv_acc_mode_index_mapping)\n",
    "    df['driving_access'] = driving_access_skims[df.period, df.driving_access_mode_index,\n",
    "                                                df.origin -1, df.destination -1]\n",
    "\n",
    "    df['VMT'] = df['driving_access']\n",
    "    df['VMT'] = df.VMT.mask(df.trip_mode.isin(['DRIVEALONEFREE','DRIVEALONEPAY']),\n",
    "                            df.dist_miles)\n",
    "    df['VMT'] = df.VMT.mask(df.trip_mode.isin(['SHARED2FREE','SHARED2PAY']),\n",
    "                            df.dist_miles/2)\n",
    "    df['VMT'] = df.VMT.mask(df.trip_mode.isin(['SHARED3FREE','SHARED3PAY']),\n",
    "                            df.dist_miles/3)\n",
    "    df['VMT'] = df.VMT.mask(df.trip_mode.isin(['TNC_SINGLE']), df.dist_miles)\n",
    "    df['VMT'] = df.VMT.mask(df.trip_mode.isin(['TNC_SHARED']), df.dist_miles/2.5)\n",
    "    df['VMT'] = df.VMT.mask(df.trip_mode.isin(['TAXI']), df.dist_miles)\n",
    "    \n",
    "    land_use['area_type'] = land_use['area_type'].replace(area_type)\n",
    "\n",
    "    # Add Trips Variables\n",
    "    df['c_ivt'] = df['primary_purpose'].replace(ivt_mapping)\n",
    "\n",
    "    #Add socio-economic variables\n",
    "    df_trips = df.merge(households[['income','lcm_county_id', 'TAZ']], how = 'left',\n",
    "            left_on = 'household_id', right_index = True)\n",
    "\n",
    "    df_trips = df_trips.merge(persons[['race','hispanic','value_of_time']], how = 'left',\n",
    "                         left_on = 'person_id', right_index = True)\n",
    "    \n",
    "    df_trips = df_trips.merge(land_use[['area_type']], how = 'left', \n",
    "                             left_on = 'TAZ', right_index = True)\n",
    "    \n",
    "\n",
    "#     print('Mean TRIP VOT: {}'.format(df_trips['value_of_time'].mean()))\n",
    "\n",
    "    df_trips['income_category'] = pd.cut(df_trips.income,\n",
    "                                         [-np.inf, 80000, 150000, np.inf],\n",
    "                                         labels = ['low', 'middle','high'])\n",
    "\n",
    "    df_trips['c_cost'] = (0.60 * df_trips['c_ivt'])/(df_trips['value_of_time'])\n",
    "    df_trips['cs'] = df_trips['mode_choice_logsum']/(-1 * df_trips['c_cost'].mean())\n",
    "    print(df_trips['c_cost'].mean())\n",
    "\n",
    "    df_trips['hispanic'] = df_trips['hispanic'].replace(hispanic)\n",
    "    df_trips['lcm_county_id'] = df_trips['lcm_county_id'].replace(county_mapping)\n",
    "\n",
    "    ## Modify persons table\n",
    "    df_persons = persons.copy()\n",
    "\n",
    "    df_persons = df_persons.merge(households[['income','lcm_county_id']],\n",
    "                                  how = 'left',\n",
    "                                  left_on = 'household_id',\n",
    "                                  right_index = True)\n",
    "    \n",
    "    df_persons = df_persons.merge(land_use[['area_type']], how = 'left', \n",
    "                             left_on = 'TAZ', right_index = True)\n",
    "\n",
    "    df_persons['income_category'] = pd.cut(df_persons.income,\n",
    "                                         [-np.inf, 80000, 150000, np.inf],\n",
    "                                         labels = ['low', 'middle','high'])\n",
    "    df_persons['lcm_county_id'] = df_persons['lcm_county_id'].replace(county_mapping)\n",
    "    df_persons['hispanic'] = df_persons['hispanic'].replace(hispanic)\n",
    "\n",
    "#     print('Trips shape, after merging: {}'.format(df_trips.shape))\n",
    "#     print('Persons shape after merging: {}'.format(df_persons.shape))\n",
    "#     print('Sum of c_cost: {}'.format(df_trips['c_cost'].sum()))\n",
    "#     print('Sum of c_ivt: {}'.format(df_trips['c_ivt'].sum()))\n",
    "#     print('Sum of value of time: {}'.format(df_trips['value_of_time'].sum()))\n",
    "#     print('Sum of cs: {}'.format(df_trips['cs'].sum()))\n",
    "    return df_trips, df_persons\n",
    "\n",
    "############################\n",
    "## Performance Indicators ##\n",
    "############################\n",
    "\n",
    "\n",
    "## VMT ##\n",
    "#########\n",
    "\n",
    "def total_vmt(trips):\n",
    "    logging.info('Calulating total VMT...')\n",
    "    return float(trips['VMT'].sum())\n",
    "\n",
    "def vmt_per_capita(trips, persons):\n",
    "    logging.info('Calulating VMT per capita...')\n",
    "    n = len(persons)\n",
    "    total = trips['VMT'].sum()\n",
    "    return float(total/n)\n",
    "\n",
    "def vmt_per_capita_income(trips, persons):\n",
    "    logging.info('Calulating VMT per capita by income...')\n",
    "    persons_segment = persons.groupby('income_category')['PNUM'].count()\n",
    "    total_segment = trips.groupby('income_category').agg({'VMT':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['VMT']\n",
    "\n",
    "def vmt_per_capita_race(trips, persons):\n",
    "    logging.info('Calulating VMT per capita by race...')\n",
    "    persons_segment = persons.groupby('race')['PNUM'].count()\n",
    "    total_segment = trips.groupby('race').agg({'VMT':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['VMT']\n",
    "\n",
    "def vmt_per_capita_hispanic(trips, persons):\n",
    "    logging.info('Calulating VMT per capita by hispanic...')\n",
    "    persons_segment = persons.groupby('hispanic')['PNUM'].count()\n",
    "    total_segment = trips.groupby('hispanic').agg({'VMT':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['VMT']\n",
    "\n",
    "def vmt_per_capita_county(trips, persons):\n",
    "    logging.info('Calulating VMT per capita by county...')\n",
    "    persons_segment = persons.groupby('lcm_county_id')['PNUM'].count()\n",
    "    total_segment = trips.groupby('lcm_county_id').agg({'VMT':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['VMT']\n",
    "\n",
    "def vmt_per_capita_urban(trips, persons):\n",
    "    logging.info('Calulating VMT per capita by urban classification...')\n",
    "    persons_segment = persons.groupby('area_type')['PNUM'].count()\n",
    "    total_segment = trips.groupby('area_type').agg({'VMT':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['VMT']\n",
    "\n",
    "## Consumer Surplus ##\n",
    "######################\n",
    "def total_consumer_surplus(df):\n",
    "    logging.info('Calulating consumer surplus...')\n",
    "    return float(df['cs'].sum())\n",
    "\n",
    "def consumer_surplus_per_capita(trips, persons):\n",
    "    logging.info('Calulating average consumer surplus...')\n",
    "    n = len(persons)\n",
    "    total = trips['cs'].sum()\n",
    "    return float(total/n)\n",
    "\n",
    "def consumer_surplus_per_capita_income(trips, persons):\n",
    "    logging.info('Calulating average consumer surplus by income...')\n",
    "    persons_segment = persons.groupby('income_category')['PNUM'].count()\n",
    "    total_segment = trips.groupby('income_category').agg({'cs':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['cs']\n",
    "\n",
    "def consumer_surplus_per_capita_race(trips, persons):\n",
    "    logging.info('Calulating average consumer surplus by race...')\n",
    "    persons_segment = persons.groupby('race')['PNUM'].count()\n",
    "    total_segment = trips.groupby('race').agg({'cs':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['cs']\n",
    "\n",
    "def consumer_surplus_per_capita_hispanic(trips, persons):\n",
    "    logging.info('Calulating average consumer surplus by hispanic...')\n",
    "    persons_segment = persons.groupby('hispanic')['PNUM'].count()\n",
    "    total_segment = trips.groupby('hispanic').agg({'cs':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['cs']\n",
    "\n",
    "def consumer_surplus_per_capita_county(trips, persons):\n",
    "    logging.info('Calulating average consumer surplus by county...')\n",
    "    persons_segment = persons.groupby('lcm_county_id')['PNUM'].count()\n",
    "    total_segment = trips.groupby('lcm_county_id').agg({'cs':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['cs']\n",
    "\n",
    "def consumer_surplus_per_capita_urban(trips, persons):\n",
    "    logging.info('Calulating average consumer surplus by county...')\n",
    "    persons_segment = persons.groupby('area_type')['PNUM'].count()\n",
    "    total_segment = trips.groupby('area_type').agg({'cs':'sum'})\n",
    "    kpi = total_segment.div(persons_segment, axis = 0)\n",
    "    return kpi.to_dict()['cs']\n",
    "\n",
    "\n",
    "## others ##\n",
    "############\n",
    "def transit_ridersip(trips):\n",
    "    logging.info('Calulating transit ridership...')\n",
    "    return int(trips.carb_mode.isin(['Public Transit']).sum())\n",
    "\n",
    "def mode_shares(trips):\n",
    "    logging.info('Calulating mode shares...')\n",
    "    ms = trips.carb_mode.value_counts(normalize=True)\n",
    "    return ms.to_dict()\n",
    "\n",
    "def mode_shares_trips(trips):\n",
    "    logging.info('Calulating mode shares trips...')\n",
    "    ms = trips.carb_mode.value_counts(normalize=False)\n",
    "    return ms.to_dict()\n",
    "\n",
    "def average_vehicle_ownership(households):\n",
    "    logging.info('Calulating vehicle ownership...')\n",
    "    return float(households.auto_ownership.mean())\n",
    "\n",
    "def seat_utilization(trips):\n",
    "    logging.info('Calulating seat utilization...')\n",
    "    veh_1 = int(trips['trip_mode'].isin(['DRIVEALONEFREE','DRIVEALONEPAY']).sum())\n",
    "    veh_2 = int(trips['trip_mode'].isin(['SHARED2FREE','SHARED2PAY']).sum())\n",
    "    veh_3 = int(trips['trip_mode'].isin(['SHARED3FREE','SHARED3PAY']).sum())\n",
    "    return float((veh_1 + veh_2 + veh_3)/(veh_1 + veh_2/2 + veh_3/3))\n",
    "\n",
    "def average_traveltime_purpose(trips):\n",
    "    logging.info('Calulating average travel time by purpose...')\n",
    "    s = trips.groupby('commute').agg({'travel_time':'mean'})\n",
    "    return s.to_dict()['travel_time']\n",
    "\n",
    "def average_traveltime_mode(trips):\n",
    "    logging.info('Calulating average travel time by mode...')\n",
    "    s = trips.groupby('carb_mode').agg({'travel_time':'mean'})\n",
    "    return s.to_dict()['travel_time']\n",
    "\n",
    "def average_traveltime_income(trips):\n",
    "    logging.info('Calulating average travel time by income...')\n",
    "    s = trips.groupby('income_category').agg({'travel_time':'mean'})\n",
    "    return s.to_dict()['travel_time']\n",
    "\n",
    "def average_commute_trip_lenght(trips):\n",
    "    logging.info('Calulating average commute trip lenght...')\n",
    "    s = trips.groupby('carb_mode').agg({'dist_miles':'mean'})\n",
    "    return s.to_dict()['dist_miles']\n",
    "\n",
    "def kpi_results_test(scenario, trips, households, persons, skims, land_use):\n",
    "    \n",
    "    mapping = read_yaml('../mapping.yaml')\n",
    "    \n",
    "    trips_ , persons_ = add_results_variables(mapping, trips, households, persons, skims, land_use)\n",
    "    \n",
    "    dict_results = {}\n",
    "    dict_results['policy'] = scenario[3:-5]\n",
    "    dict_results['name'] = scenario\n",
    "\n",
    "    #Vmt KPIS\n",
    "    dict_results['total_vmt'] = total_vmt(trips_)\n",
    "    dict_results['vmt_per_capita'] = vmt_per_capita(trips_, persons_)\n",
    "    dict_results['vmt_per_capita_income'] = vmt_per_capita_income(trips_, persons_)\n",
    "    dict_results['vmt_per_capita_race'] = vmt_per_capita_race(trips_, persons_)\n",
    "    dict_results['vmt_per_capita_hispanic'] = vmt_per_capita_hispanic(trips_, persons_)\n",
    "    dict_results['vmt_per_capita_county'] = vmt_per_capita_county(trips_, persons_)\n",
    "    dict_results['vmt_per_capita_urban'] = vmt_per_capita_urban(trips_, persons_)\n",
    "\n",
    "    #Consumer Surplus KPIs\n",
    "    dict_results['total_cs'] = total_consumer_surplus(trips_)\n",
    "    dict_results['cs_per_capita'] = consumer_surplus_per_capita(trips_, persons_)\n",
    "    dict_results['cs_per_capita_income'] = consumer_surplus_per_capita_income(trips_, persons_)\n",
    "    dict_results['cs_per_capita_race'] = consumer_surplus_per_capita_race(trips_, persons_)\n",
    "    dict_results['cs_per_capita_hispanic'] = consumer_surplus_per_capita_hispanic(trips_, persons_)\n",
    "    dict_results['cs_per_capita_county'] = consumer_surplus_per_capita_county(trips_, persons_)\n",
    "    dict_results['cs_per_capita_urban'] = consumer_surplus_per_capita_urban(trips_, persons_)\n",
    "\n",
    "    #Other\n",
    "    dict_results['transit_ridersip'] = transit_ridersip(trips_)\n",
    "    dict_results['mode_shares'] = mode_shares(trips_)\n",
    "    dict_results['mode_shares_trips'] = mode_shares_trips(trips_)\n",
    "    dict_results['average_vehicle_ownership'] = average_vehicle_ownership(households)\n",
    "    dict_results['seat_utilization'] = seat_utilization(trips_)\n",
    "    dict_results['average_traveltime_purpose'] = average_traveltime_purpose(trips_)\n",
    "    dict_results['average_traveltime_mode'] = average_traveltime_mode(trips_)\n",
    "    dict_results['average_traveltime_income'] = average_traveltime_income(trips_)\n",
    "    dict_results['average_commute_trip_lenght'] = average_commute_trip_lenght(trips_)\n",
    "\n",
    "    return dict_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-shannon",
   "metadata": {},
   "source": [
    "# Re-estimate KPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_kpi(scenario):\n",
    "    \n",
    "    #Read trips table\n",
    "    trips_fpath = os.path.join(scenario, \"final_trips.csv\")\n",
    "    trips = read_csv(trips_fpath, index_col = 'trip_id', dytpe = {'origin':int, 'destination':int} )\n",
    "    \n",
    "    # Read households table\n",
    "    households_fpath = os.path.join(scenario, \"final_households.csv\")\n",
    "    households = read_csv(households_fpath, index_col = 'household_id')\n",
    "    \n",
    "    # Read persons Table\n",
    "    persons_fpath = os.path.join(scenario, \"final_persons.csv\")\n",
    "    persons = read_csv(persons_fpath, index_col = 'person_id')\n",
    "    \n",
    "    # Read skims\n",
    "    skims_fpath = f\"../skims/{scenario}_skims.omx\"\n",
    "    download_s3(skims_fpath, 'carb-results', f\"{scenario}/skims.omx\")\n",
    "    skims = omx.open_file(skims_fpath, mode = 'r')\n",
    "    \n",
    "    # Read land use table\n",
    "    land_use_fpath = os.path.join(scenario, \"final_land_use.csv\")\n",
    "    land_use = read_csv(land_use_fpath, index_col = 'TAZ')\n",
    "    \n",
    "    # Re-estimate results \n",
    "    results = kpi_results_test(scenario, trips, households, persons, skims, land_use)\n",
    "    \n",
    "    # Save yaml \n",
    "    yaml_fpath = f\"updated_kpi_{scenario}.yaml\"\n",
    "    save_yaml(yaml_fpath, results)\n",
    "\n",
    "    #Upload to S3 Bucket\n",
    "    s3_name = f\"{scenario}/{yaml_fpath}\"\n",
    "    upload_file_s3(yaml_fpath, bucket = 'carb-results', object_name=s3_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "better-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = pd.Series(os.listdir('../kpis'))\n",
    "scenarios = scenarios[scenarios.str.contains('.yaml')].str[4:-5]\n",
    "scenarios = list(scenarios.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fiscal-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-estiamting scenario 54_base_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/activitysim/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 19:31:59,258 __main__ - INFO - Downloading 54_base_000/skims.omx\n",
      "[==================================================]-0.0033255221429710734\n",
      "2023-03-19 19:34:36,550 root - INFO - Calulating total VMT...\n",
      "2023-03-19 19:34:36,641 root - INFO - Calulating VMT per capita...\n",
      "2023-03-19 19:34:36,728 root - INFO - Calulating VMT per capita by income...\n",
      "2023-03-19 19:34:45,004 root - INFO - Calulating VMT per capita by race...\n",
      "2023-03-19 19:34:46,581 root - INFO - Calulating VMT per capita by hispanic...\n",
      "2023-03-19 19:34:48,399 root - INFO - Calulating VMT per capita by county...\n",
      "2023-03-19 19:34:50,215 root - INFO - Calulating VMT per capita by urban classification...\n",
      "2023-03-19 19:34:51,908 root - INFO - Calulating consumer surplus...\n",
      "2023-03-19 19:34:51,995 root - INFO - Calulating average consumer surplus...\n",
      "2023-03-19 19:34:52,082 root - INFO - Calulating average consumer surplus by income...\n",
      "2023-03-19 19:34:52,300 root - INFO - Calulating average consumer surplus by race...\n",
      "2023-03-19 19:34:53,907 root - INFO - Calulating average consumer surplus by hispanic...\n",
      "2023-03-19 19:34:55,752 root - INFO - Calulating average consumer surplus by county...\n",
      "2023-03-19 19:34:57,534 root - INFO - Calulating average consumer surplus by county...\n",
      "2023-03-19 19:34:59,182 root - INFO - Calulating transit ridership...\n",
      "2023-03-19 19:34:59,923 root - INFO - Calulating mode shares...\n",
      "2023-03-19 19:35:02,333 root - INFO - Calulating mode shares trips...\n",
      "2023-03-19 19:35:04,747 root - INFO - Calulating vehicle ownership...\n",
      "2023-03-19 19:35:04,752 root - INFO - Calulating seat utilization...\n",
      "2023-03-19 19:35:07,251 root - INFO - Calulating average travel time by purpose...\n",
      "2023-03-19 19:35:08,706 root - INFO - Calulating average travel time by mode...\n",
      "2023-03-19 19:35:10,184 root - INFO - Calulating average travel time by income...\n",
      "2023-03-19 19:35:10,369 root - INFO - Calulating average commute trip lenght...\n",
      "Time: 327.92 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for scenario in ['54_base_000']:\n",
    "    print(f'Re-estiamting scenario {scenario}')\n",
    "    start = time.time()\n",
    "    rewrite_kpi(scenario)\n",
    "    end = time.time()\n",
    "    print(f\"Time: {end - start:.2f} seconds\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
